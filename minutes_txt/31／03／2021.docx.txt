Participants:

Bettina Klimek (BK)

Fahad Khan (FK)

Julia Bosque-Gil (JBG)

Matteo Pellegrini

Max Ionov (GUF)

Agenda

Update by JBG on confirmation from OntoLex chairs that it’s OK to create a
partially redundant model with the decomp module:

  • 
        JBG: Contacted co-chairs, we will discuss this in a telco after the
        Easter break (together with the W3C Day schedule)

Lila group follow-up on last telco

  • 
        made changes on compounding example

      □ 
            added lexinfo part of speech

      □ 
            added individual rules specific to lexemes involved and which are
            subclasses of superclass rules

      □ 
            wordformation relation relates 2 lexemes and do only have one
            source and target because vartrans:lexicalRel allows exactly one
            source and target, lila group satisfied with this

Setup for testing pipeline

2 evaluation tests required:

 1.
        for static conversion of input data into OntoLex-Morph (only manual
        evaluation of modeling needs in evaluation sheet)

 2.
        autogeneration of additional resources of OntoLex-Morph RDF data based
        on converted source dataset into OntoLex-Morph RDF

Input data

  • 
        autogeneration part of module is the syntax (= vocabulary) that allows
        to generate resources, specifies how resources are generated

  • 
        rules are required to apply the autogeneration syntax of the module in
        the first place and then they have to be converted into the morph
        module syntax/rules (which is out of scope of the morph module!)

  • 
        can we represent rule of input data in module syntax? → add this as
        modeling need (BK)!

  • 
        Data format for testing autogeneration: current test data not in RDF -
        source/input data has to be already in OntoLex-Morph RDF

  • 
        Extent? with/without morph:Morph resources or only ontolex:LexicalEntry
        and ontolex:Form

  • 

Module draft

  • 
        OWL file required? Upload to git repo?

  • 
        SPARQL queries?!

Output data

  • 
        Separate file or integrated into ontolex input dataset?

  • 
        If generated output will it be integrated into existing OntoLex dataset
        already containing morphological data? Additional indication to
        differentiate generated vs. existing data?

  • 
        Granularity:

      □ 
            ontolex:LexicalEntry/ontolex:Form resources only

      □ 
            ontolex:LexicalEntry/ontolex:Form resources + morph:Morph resources

      □ 
            ontolex:LexicalEntry/ontolex:Form resources + morph resources +
            interrelation between ontolex:LexicalEntry/ontolex:Form and
            morph:Morph resources

Testing documentation

  • 
        Table with all modeling needs, stated input data and underlying
        modeling draft OWL file

  • 
        documentation of evaluation on results of output data against modeling
        needs

  • 
        Separate place to store input and output data?

[image1]

Decisions on further progress:

 1.
        in the next telco on April 14th we will go through the module OWL file
        and evaluation sheet as the starting point for evaluating and
        developing the module vocabulary

 2.
        every following telco we will go through example data and filll in the
        evaluation table

 3.
        after that we will apply the collected “required adaptions” to the OWL
        file and evaluate the next example dataset - repeat until vocabulary is
        validated

 4.
        Apply testing for a whole dataset converted into OntoLex-Morph RDF

Todos for next telco:

  • 
        Max will update OWL file with his latest suggestion for inflection and
        the latest Lila proposal for representing compounding and derivation

  • 
        Bettina will sort and update modeling needs

